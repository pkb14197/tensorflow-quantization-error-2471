{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = \"../Trainingdata/splitpre2701515/train\"\n",
    "validpath = \"../Trainingdata/splitpre2701515/val\"\n",
    "testpath = \"../Trainingdata/splitpre2701515/test\"\n",
    "train_labels = os.listdir(trainpath)\n",
    "num_classes=len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xsize=224\n",
    "ysize=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modelnet(input_shape=None, pooling=None, classes=None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = BatchNormalization(name='BN1')(x)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "\n",
    "    x = Convolution2D(128, (3, 3), strides=(2, 2), padding='valid', name='conv2')(x)\n",
    "    x = BatchNormalization(name='BN2')(x)\n",
    "    x = Activation('relu', name='relu_conv2')(x)\n",
    "\n",
    "    x = Convolution2D(128, (3, 3), strides=(2, 2), padding='valid', name='conv3')(x)\n",
    "    x = BatchNormalization(name='BN3')(x)\n",
    "    x = Activation('relu', name='relu_conv3')(x)\n",
    "\n",
    "    x = Convolution2D(256, (3, 3), strides=(2, 2), padding='valid', name='conv4')(x)\n",
    "    x = BatchNormalization(name='BN4')(x)\n",
    "    x = Activation('relu', name='relu_conv4')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop1')(x)\n",
    "    x = Convolution2D(num_classes, (1, 1), padding='valid', name='convf')(x)\n",
    "    x = Activation('relu', name='relu_convf')(x)\n",
    "    \n",
    "    if pooling == 'avg':\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "    elif pooling=='max':\n",
    "        x = GlobalMaxPooling2D()(x)\n",
    "    elif pooling==None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Unknown argument for 'pooling'=\" + pooling)\n",
    "\n",
    "    inputs = img_input\n",
    "    preds = Activation('softmax', name='loss')(x)\n",
    "    model = Model(inputs, preds, name='Modelnet')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Modelnet(input_shape=(xsize, ysize,3), pooling = 'avg', classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 796 images belonging to 5 classes.\n",
      "Found 171 images belonging to 5 classes.\n",
      "Found 173 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)                               \n",
    "train_generator=train_datagen.flow_from_directory(trainpath,\n",
    "                                                  target_size=(xsize, ysize),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=16,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True)\n",
    "\n",
    "valid_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_generator = valid_datagen.flow_from_directory(validpath,\n",
    "                                                         target_size=(xsize, ysize),\n",
    "                                                         color_mode='rgb',\n",
    "                                                         batch_size=16,\n",
    "                                                         class_mode='categorical',\n",
    "                                                         shuffle=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(testpath,\n",
    "                                                         target_size=(xsize, ysize),\n",
    "                                                         color_mode='rgb',\n",
    "                                                         batch_size=1,\n",
    "                                                         class_mode=None,\n",
    "                                                         shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnrate=1e-3\n",
    "# sgd = SGD(lr=learnrate,momentum=0.9,decay=0.00025) #SGD\n",
    "opt=Adam(lr=learnrate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 10 173\n"
     ]
    }
   ],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "step_size_vali=validation_generator.n//validation_generator.batch_size\n",
    "step_size_test=test_generator.n//test_generator.batch_size\n",
    "print(step_size_train, step_size_vali, step_size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-ea5a26e74522>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "49/49 [==============================] - 29s 599ms/step - loss: 0.8743 - accuracy: 0.6513 - val_loss: 2.4413 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 43s 881ms/step - loss: 0.5610 - accuracy: 0.7731 - val_loss: 3.8132 - val_accuracy: 0.2250\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 29s 592ms/step - loss: 0.4074 - accuracy: 0.8577 - val_loss: 5.2641 - val_accuracy: 0.2062\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 30s 602ms/step - loss: 0.3401 - accuracy: 0.8731 - val_loss: 4.4014 - val_accuracy: 0.2188\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 30s 619ms/step - loss: 0.3076 - accuracy: 0.8949 - val_loss: 5.4865 - val_accuracy: 0.2062\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 30s 606ms/step - loss: 0.2259 - accuracy: 0.9333 - val_loss: 3.9908 - val_accuracy: 0.2750\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 29s 598ms/step - loss: 0.2230 - accuracy: 0.9346 - val_loss: 3.5445 - val_accuracy: 0.3313\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 30s 619ms/step - loss: 0.1513 - accuracy: 0.9577 - val_loss: 1.8173 - val_accuracy: 0.5188\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 29s 590ms/step - loss: 0.1522 - accuracy: 0.9423 - val_loss: 0.9234 - val_accuracy: 0.7063\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 29s 597ms/step - loss: 0.1431 - accuracy: 0.9590 - val_loss: 0.9345 - val_accuracy: 0.7437\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=train_generator,\n",
    "                            steps_per_epoch=step_size_train,\n",
    "                            epochs=10,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=step_size_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to:  ownmodel_ori.h5\n"
     ]
    }
   ],
   "source": [
    "# prune the model----------------------------------------\n",
    "orifile = 'ownmodel_ori.h5'\n",
    "print('Saving model to: ', orifile)\n",
    "models.save_model(model, orifile, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-0abcf9207136>:5: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "173/173 [==============================] - 2s 11ms/step\n",
      "--- 2.059000253677368 seconds ---\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "start_time = time.time()\n",
    "predo=model.predict_generator(test_generator,\n",
    "                             steps=step_size_test,\n",
    "                             verbose=1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity import keras as sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "735\n"
     ]
    }
   ],
   "source": [
    "# Load the serialized model\n",
    "loaded_model = models.load_model(orifile)\n",
    "newepochs = 15\n",
    "end_step = step_size_train * newepochs\n",
    "print(end_step)\n",
    "\n",
    "new_pruning_params = {\n",
    "      'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                   final_sparsity=0.9,\n",
    "                                                   begin_step=0,\n",
    "                                                   end_step=end_step,\n",
    "                                                   frequency=80)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Bojie\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\sparsity\\keras\\pruning_wrapper.py:199: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "new_pruned_model = sparsity.prune_low_magnitude(loaded_model, **new_pruning_params)\n",
    "\n",
    "opa=Adam(lr=learnrate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "new_pruned_model.compile(\n",
    "    loss='categorical_crossentropy',#tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=opa,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "49/49 [==============================] - 31s 630ms/step - loss: 0.1371 - accuracy: 0.9692 - val_loss: 0.3162 - val_accuracy: 0.8625\n",
      "Epoch 2/15\n",
      "49/49 [==============================] - 42s 864ms/step - loss: 0.1957 - accuracy: 0.9423 - val_loss: 0.8356 - val_accuracy: 0.6250\n",
      "Epoch 3/15\n",
      "49/49 [==============================] - 29s 593ms/step - loss: 0.1001 - accuracy: 0.9756 - val_loss: 0.2318 - val_accuracy: 0.9187\n",
      "Epoch 4/15\n",
      "49/49 [==============================] - 29s 596ms/step - loss: 0.2512 - accuracy: 0.9154 - val_loss: 0.2286 - val_accuracy: 0.9500\n",
      "Epoch 5/15\n",
      "49/49 [==============================] - 29s 599ms/step - loss: 0.2140 - accuracy: 0.9346 - val_loss: 2.5590 - val_accuracy: 0.4688\n",
      "Epoch 6/15\n",
      "49/49 [==============================] - 32s 648ms/step - loss: 0.2445 - accuracy: 0.9269 - val_loss: 0.2716 - val_accuracy: 0.9062\n",
      "Epoch 7/15\n",
      "49/49 [==============================] - 29s 592ms/step - loss: 0.2615 - accuracy: 0.9192 - val_loss: 0.6498 - val_accuracy: 0.7063\n",
      "Epoch 8/15\n",
      "49/49 [==============================] - 30s 604ms/step - loss: 0.1380 - accuracy: 0.9731 - val_loss: 0.2422 - val_accuracy: 0.9500\n",
      "Epoch 9/15\n",
      "49/49 [==============================] - 32s 647ms/step - loss: 0.2375 - accuracy: 0.9269 - val_loss: 0.3808 - val_accuracy: 0.9438\n",
      "Epoch 10/15\n",
      "49/49 [==============================] - 35s 708ms/step - loss: 0.1942 - accuracy: 0.9359 - val_loss: 0.8220 - val_accuracy: 0.6313\n",
      "Epoch 11/15\n",
      "49/49 [==============================] - 33s 665ms/step - loss: 0.1766 - accuracy: 0.9667 - val_loss: 0.4349 - val_accuracy: 0.8875\n",
      "Epoch 12/15\n",
      "49/49 [==============================] - 31s 623ms/step - loss: 0.1812 - accuracy: 0.9641 - val_loss: 0.4923 - val_accuracy: 0.8375\n",
      "Epoch 13/15\n",
      "49/49 [==============================] - 35s 704ms/step - loss: 0.1422 - accuracy: 0.9667 - val_loss: 0.4255 - val_accuracy: 0.8687\n",
      "Epoch 14/15\n",
      "49/49 [==============================] - 30s 604ms/step - loss: 0.1248 - accuracy: 0.9731 - val_loss: 0.1945 - val_accuracy: 0.9937\n",
      "Epoch 15/15\n",
      "49/49 [==============================] - 30s 622ms/step - loss: 0.0833 - accuracy: 0.9859 - val_loss: 0.1681 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    sparsity.UpdatePruningStep()\n",
    "    ]\n",
    "history=new_pruned_model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=step_size_train,\n",
    "                            epochs=newepochs,\n",
    "                            verbose=1,\n",
    "                            initial_epoch = 0,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=step_size_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-939493100dd6>:3: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "Accuracy:  0.9375\n",
      "Loss:  0.1765105426311493\n"
     ]
    }
   ],
   "source": [
    "loss, acc=new_pruned_model.evaluate_generator(generator=validation_generator,\n",
    "                                    steps=step_size_vali,\n",
    "                                    verbose=0)\n",
    "print(\"Accuracy: \" ,acc)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = sparsity.strip_pruning(new_pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunedfile='ownmodel_pruW.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving pruned model to:  ownmodel_pruW.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Accuracy:  0.9375\n",
      "Loss:  0.1744621843099594\n"
     ]
    }
   ],
   "source": [
    "print('Saving pruned model to: ', prunedfile)\n",
    "models.save_model(final_model, prunedfile, \n",
    "                        include_optimizer=False)\n",
    "model=models.load_model(prunedfile)\n",
    "model.compile(optimizer=opa,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "loss, acc=model.evaluate_generator(generator=validation_generator,\n",
    "                                    steps=step_size_vali)\n",
    "print(\"Accuracy: \" ,acc)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1/kernel:0 -- Total:1728, zero:89.98842592592592\n",
      "conv1/bias:0 -- Total:64, zero:0.0\n",
      "BN1/gamma:0 -- Total:64, zero:0.0\n",
      "BN1/beta:0 -- Total:64, zero:0.0\n",
      "BN1/moving_mean:0 -- Total:64, zero:0.0\n",
      "BN1/moving_variance:0 -- Total:64, zero:0.0\n",
      "conv2/kernel:0 -- Total:73728, zero:89.99972873263889\n",
      "conv2/bias:0 -- Total:128, zero:0.0\n",
      "BN2/gamma:0 -- Total:128, zero:0.0\n",
      "BN2/beta:0 -- Total:128, zero:0.0\n",
      "BN2/moving_mean:0 -- Total:128, zero:0.0\n",
      "BN2/moving_variance:0 -- Total:128, zero:0.0\n",
      "conv3/kernel:0 -- Total:147456, zero:89.99972873263889\n",
      "conv3/bias:0 -- Total:128, zero:0.0\n",
      "BN3/gamma:0 -- Total:128, zero:0.0\n",
      "BN3/beta:0 -- Total:128, zero:0.0\n",
      "BN3/moving_mean:0 -- Total:128, zero:0.0\n",
      "BN3/moving_variance:0 -- Total:128, zero:0.0\n",
      "conv4/kernel:0 -- Total:294912, zero:89.99972873263889\n",
      "conv4/bias:0 -- Total:256, zero:0.0\n",
      "BN4/gamma:0 -- Total:256, zero:0.0\n",
      "BN4/beta:0 -- Total:256, zero:0.0\n",
      "BN4/moving_mean:0 -- Total:256, zero:0.0\n",
      "BN4/moving_variance:0 -- Total:256, zero:0.0\n",
      "convf/kernel:0 -- Total:1280, zero:90.0\n",
      "convf/bias:0 -- Total:5, zero:0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np    \n",
    "for i, w in enumerate(model.get_weights()):\n",
    "    print('{} -- Total:{}, zero:{}'.format(\n",
    "            model.weights[i].name,w.size,np.sum(w==0)/w.size*100)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned model before compression: 2086.86 KB\n",
      "Size of the pruned model after compression: 404.86 KB\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip3='ownsque_pruW.zip'\n",
    "with zipfile.ZipFile(zip3, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(prunedfile)\n",
    "print(\"Size of the pruned model before compression: %.2f KB\" \n",
    "      % (os.path.getsize(prunedfile) / float(2**10)))\n",
    "print(\"Size of the pruned model after compression: %.2f KB\" \n",
    "      % (os.path.getsize(zip3) / float(2**10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unpruned model before compression: 2086.86 KB\n",
      "Size of the unpruned model after compression: 1895.70 KB\n"
     ]
    }
   ],
   "source": [
    "zip1='ownsque_ori.zip'\n",
    "with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(orifile)\n",
    "print(\"Size of the unpruned model before compression: %.2f KB\" % \n",
    "      (os.path.getsize(orifile) / float(2**10)))\n",
    "print(\"Size of the unpruned model after compression: %.2f KB\" % \n",
    "      (os.path.getsize(zip1) / float(2**10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 2s 11ms/step\n",
      "--- 2.1210005283355713 seconds ---\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "start_time = time.time()\n",
    "pred=model.predict_generator(test_generator,\n",
    "                             steps=step_size_test,\n",
    "                             verbose=1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "#print(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.95\n",
      "recall = 0.96\n",
      "f1 = 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "print('precision = {0:.2f}'.format(precision_score(test_generator.classes, predicted_class_indices, average=\"macro\")))\n",
    "print('recall = {0:.2f}'.format(recall_score(test_generator.classes, predicted_class_indices, average=\"macro\")))\n",
    "print('f1 = {0:.2f}'.format(f1_score(test_generator.classes, predicted_class_indices, average=\"macro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "ground_truth = test_generator.classes\n",
    "fnames = test_generator.filenames\n",
    "label2index = test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({\"Filename\":fnames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"resultsownnet.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of errors = 9/173 = 0.05202312138728324\n"
     ]
    }
   ],
   "source": [
    "errors = np.where(predicted_class_indices != ground_truth)[0]\n",
    "eresult=len(errors)/len(ground_truth)\n",
    "print(\"No of errors = {}/{} = {}\".format(len(errors),len(ground_truth),eresult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eagerly enabled:  True\n",
      "2.3.0-dev20200515\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  import tensorflow.compat.v2 as tf\n",
    "except Exception:\n",
    "    pass\n",
    "tf.enable_v2_behavior()\n",
    "print(\"Eagerly enabled: \", tf.executing_eagerly())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From C:\\Users\\Bojie\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:465: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:tensorflow:From C:\\Users\\Bojie\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:105: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Bojie\\AppData\\Local\\Temp\\tmpzpetbq8v\\assets\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "See console for info.\n2020-05-16 17:48:30.914124: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.914668: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\n2020-05-16 17:48:30.914953: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\n2020-05-16 17:48:30.915355: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\n2020-05-16 17:48:30.915642: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\n2020-05-16 17:48:30.916110: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.916375: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.916600: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.916858: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.917086: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.917327: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.917546: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.917845: F tensorflow/lite/toco/tooling_util.cc:627] Check failed: dim >= 1 (-1 vs. 1)\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6a6bc44edca5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# converter.target_spec.supported_types = [tf.float16]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     return super(TFLiteKerasModelConverterV2,\n\u001b[1;32m--> 689\u001b[1;33m                  self).convert(graph_def, input_tensors, output_tensors)\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, graph_def, input_tensors, output_tensors)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         **converter_kwargs)\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mquant_mode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_training_int8_no_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[1;34m(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m       \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[0mdebug_info_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdebug_info_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m       enable_mlir_converter=enable_mlir_converter)\n\u001b[0m\u001b[0;32m    555\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf23\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[1;34m(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[0;32m    257\u001b[0m       \u001b[0mstdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mConverterError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"See console for info.\\n%s\\n%s\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;31m# Must manually cleanup files.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConverterError\u001b[0m: See console for info.\n2020-05-16 17:48:30.914124: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.914668: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\n2020-05-16 17:48:30.914953: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\n2020-05-16 17:48:30.915355: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\n2020-05-16 17:48:30.915642: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\n2020-05-16 17:48:30.916110: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.916375: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.916600: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.916858: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.917086: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.917327: I tensorflow/lite/toco/import_tensorflow.cc:1324] Converting unsupported operation: FusedBatchNormV3\n2020-05-16 17:48:30.917546: I tensorflow/lite/toco/import_tensorflow.cc:1373] Unable to determine output type for op: FusedBatchNormV3\n2020-05-16 17:48:30.917845: F tensorflow/lite/toco/tooling_util.cc:627] Check failed: dim >= 1 (-1 vs. 1)\n\n\n"
     ]
    }
   ],
   "source": [
    "m1='ownmodel_pruW.h5'\n",
    "model=tf.keras.models.load_model(m1)\n",
    "tflite_model_file = 'ownnet.tflite'\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalmodel(test_generator, interpreter):\n",
    "    pre1=[]\n",
    "    for i in range(test_generator.n):\n",
    "        x= next(test_generator)\n",
    "        interpreter.set_tensor(input_index, x)\n",
    "        interpreter.invoke()\n",
    "        predictions = interpreter.get_tensor(output_index)\n",
    "    #     print(predictions)\n",
    "        predicted_class_indices1=np.argmax(predictions)#,axis=1\n",
    "    #     print(predicted_class_indices1)\n",
    "        pre1.append(predicted_class_indices1)\n",
    "    return pre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=evalmodel(test_generator, interpreter)\n",
    "print('Classification Report')\n",
    "print(classification_report(test_generator.classes, predicted_class_indices, target_names=train_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf23",
   "language": "python",
   "name": "tf23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
